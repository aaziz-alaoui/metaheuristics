{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariance-Matrix Adaptation Evolution Strategy (CMA-ES)\n",
    "\n",
    "Cet algorithme rentre dans la catégorie des algorithmes à stratégie d'évolution. Il est très performant sur les modèles continus, bruités, mal conditionnés, etc. En revanche, si l'espace de recherche est à peu de dimensions, ou si on connaît le gradient de notre fonction, d'autres méthodes sont plus efficaces. (voir *optimisation non-linéaire* avec les méthodes à base de descente de gradient, `scipy.optimize` sous Python)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib import animation\n",
    "\n",
    "import numpy as np\n",
    "import scipy.interpolate as sp\n",
    "\n",
    "def anim_to_html(anim):\n",
    "    plt.close(anim._fig)\n",
    "    return anim.to_html5_video()\n",
    "\n",
    "animation.Animation._repr_html_ = anim_to_html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour comprendre le principe de ces algorithmes, on va partir d'une fonction assez chaotique que l'on génère à partir de points tirés au hasard :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 10, 30)\n",
    "y = np.random.uniform(0, -10, 30)\n",
    "tck = sp.splrep(x, y)\n",
    "\n",
    "x_ = np.linspace(0, 10, 200)\n",
    "\n",
    "# this function returns the value of each position\n",
    "# we show it in the Y axis.\n",
    "# the lower, the better.\n",
    "def get_value(x):\n",
    "    return sp.splev(x, tck)\n",
    "\n",
    "y_ = get_value(x_)\n",
    "plt.plot(x_, y_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici on manipule une fonction à base de splines. Pour trouver le minimum de cette fonction, on peut commencer par tirer $\\lambda$ points uniformément répartis et les évaluer, puis garder les $\\mu$ meilleurs :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "λ, μ = 100, 20\n",
    "\n",
    "plt.xlim((0, 10))\n",
    "plt.ylim((-12, 0))\n",
    "plt.plot(x_, y_)\n",
    "\n",
    "x = np.random.uniform(0, 10, λ)\n",
    "y = sp.splev(x, tck)\n",
    "best = sorted(x, key=lambda x: sp.splev(x, tck))[:μ]\n",
    "plt.plot(x, y, 'o', color='#aaaaaa')\n",
    "plt.plot(best, sp.splev(best, tck), 'o', color='#aa3a3a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "À partir des $\\mu$ meilleurs points, de leur moyenne et de leur écart-type, on peut créer une nouvelle loi normale, et tirer à nouveau $\\lambda$ nouveaux points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 5))\n",
    "gs = gridspec.GridSpec(5, 1)\n",
    "\n",
    "top = plt.subplot(gs[0])\n",
    "ax = plt.subplot(gs[1:-1], sharex=top)\n",
    "bottom = plt.subplot(gs[-1], sharex=top)\n",
    "top.set_yticks([])\n",
    "bottom.set_yticks([])\n",
    "    \n",
    "λ, μ = 100, 20\n",
    "best = np.random.uniform(0, 10, λ)\n",
    "all_ = []\n",
    "\n",
    "ax.plot(x_, y_)\n",
    "\n",
    "def init():\n",
    "    global best\n",
    "    best = np.random.uniform(0, 10, λ)\n",
    "    return all_\n",
    "    \n",
    "def update(frame):\n",
    "    global best, all_\n",
    "    [a.remove() for a in all_]\n",
    "    all_.clear()\n",
    "    \n",
    "    # we model 'potentially good' solutions \n",
    "    # as a normal distribution\n",
    "    # using the μ best solutions found last time\n",
    "    avg, std = np.mean(best), np.std(best)\n",
    "    \n",
    "    # we simulate λ new solutions based on\n",
    "    # this normal distribution\n",
    "    current = np.random.normal(avg, std, λ)\n",
    "    current = current[(current < 10) & (current > 0)]\n",
    "    \n",
    "    # we choose the new μ best solutions from the recently \n",
    "    # simulated solutions\n",
    "    best = sorted(current, key=get_value)[:μ]\n",
    "    \n",
    "    all_ += ax.plot(current, sp.splev(current, tck), 'o', color=\"#aaaaaa\", alpha=.5)\n",
    "    all_ += ax.plot(best, sp.splev(best, tck), 'o', color=\"#aa3a3a\")\n",
    "\n",
    "    count, bins, ignored = bottom.hist(current, color=\"#aaaaaa\", alpha=.5, bins=30)\n",
    "    all_ += ignored\n",
    "    all_ += top.plot(bins, 1/(std * np.sqrt(2 * np.pi)) *\n",
    "                     np.exp( - (bins - avg)**2 / (2 * std**2) ),\n",
    "                     linewidth=2, color='#aaaaaa')\n",
    "    \n",
    "    count, bins, ignored = bottom.hist(best, color=\"#aa3a3a\", bins=30)\n",
    "    all_ += ignored\n",
    "    avg, std = np.mean(best), np.std(best)\n",
    "    all_ += top.plot(bins, 1/(std * np.sqrt(2 * np.pi)) *\n",
    "                     np.exp( - (bins - avg)**2 / (2 * std**2) ),\n",
    "                     linewidth=2, color='#aa3a3a')\n",
    "    \n",
    "    top.relim()\n",
    "    top.autoscale_view()\n",
    "    \n",
    "    return all_\n",
    "\n",
    "animation.FuncAnimation(fig, update, init_func=init, frames=20, interval=500, blit=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut généraliser cette méthode à $n$ dimensions. Illustrons avec les cartes 2D que nous générions pour le recuit simulé: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_boulders = 150\n",
    "boulders = np.random.uniform(0., 1., (n_boulders, 3))\n",
    "boulders[:, 2] = 1/(3 ** np.random.choice(range(2, 4), (n_boulders)))\n",
    "\n",
    "def eval_boulders(x, y, boulders = boulders):\n",
    "    res = 0\n",
    "    for i in range(boulders.shape[0]):\n",
    "        eval_ = (x - boulders[i, 0]) ** 2 + (y - boulders[i, 1]) ** 2 - boulders[i, 2] ** 2\n",
    "        if eval_ < 0:\n",
    "            res += eval_\n",
    "    return res\n",
    "\n",
    "\n",
    "X, Y = np.meshgrid(np.linspace(0, 1, 100), np.linspace(0, 1, 100))\n",
    "Z = np.zeros(X.shape)\n",
    "\n",
    "for i in range(n_boulders):\n",
    "    eval_ = (X - boulders[i, 0]) ** 2 + (Y - boulders[i, 1]) ** 2 - boulders[i, 2] ** 2\n",
    "    Z[eval_ < 0] += eval_[eval_<0]\n",
    "\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "plt.contour(X, Y, Z, alpha=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On utilise maintenant une loi normale multivariée qui implique des matrices de covariance. La diagonale de la matrice de covariance est liée à la variance d'une distribution dans chacune des dimensions, et les termes extra-diagonaux expriment la corrélation entre chacune des dimensions. Des termes extra-diagonaux positifs représentent une « ellipse » penchée d'un côté et négatifs de l'autre.\n",
    "\n",
    "En diagonalisant la matrice de covariance, on retrouve les directions dans lesquelles se répartissent nos échantillons.  \n",
    "C'est d'ailleurs sur cette diagonalisation que repose l'[Analyse en Composantes Principales](https://fr.wikipedia.org/wiki/Analyse_en_composantes_principales)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.patches import Ellipse\n",
    "import scipy.linalg as sl\n",
    "\n",
    "covs = [np.asarray([[2, 0], [0, 1]]),\n",
    "        np.asarray([[2, 1], [1, 2]]),\n",
    "        np.asarray([[2, -1], [-1, 2]]),]\n",
    "\n",
    "fig, ax = plt.subplots(1, len(covs), figsize=(15, 5))\n",
    "\n",
    "for i, cov in enumerate(covs):\n",
    "    \n",
    "    x = np.random.multivariate_normal([0, 0], cov, 100)\n",
    "    e, v = sl.eig(cov)\n",
    "    \n",
    "    angle = 0 if i == 0 else np.degrees(np.arccos(np.clip(np.dot(v[:,0], [0, 1]), -1, 1)))\n",
    "    \n",
    "    ax[i].plot(*x.T, 'o')\n",
    "    ax[i].add_patch(Ellipse([0, 0], 2*np.sqrt(5.991)*e[0].real, 2*np.sqrt(5.991)*e[1].real,\n",
    "                            angle,\n",
    "                            fc=\"#aaaaaa\"))\n",
    "    \n",
    "    ax[i].set_axis_off()\n",
    "    ax[i].axis('square')\n",
    "    ax[i].set_xlim([-6, 6])\n",
    "    ax[i].set_ylim([-6, 6])\n",
    "    ax[i].set_title(\"{}\\n{}\".format(*cov.tolist()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 7))\n",
    "ax = fig.gca()\n",
    "    \n",
    "λ, μ = 100, 20\n",
    "best = np.random.uniform(0., 1., (λ, 2))\n",
    "all_ = []\n",
    "avgs = []\n",
    "\n",
    "ax.contour(X, Y, Z, alpha=.5)\n",
    "\n",
    "def init():\n",
    "    global best\n",
    "    best = np.random.uniform(0., 1., (λ, 2))\n",
    "    return all_\n",
    "    \n",
    "def update(frame):\n",
    "    global best, all_, avgs\n",
    "    [a.remove() for a in all_]\n",
    "    all_.clear()\n",
    "    \n",
    "    avg, cov = np.mean(best, axis=0), np.cov(best.T)\n",
    "    avgs.append(avg)\n",
    "    current = np.random.multivariate_normal(avg, cov, λ)\n",
    "    mask = np.bitwise_and(np.bitwise_and(current[:,0] > 0, current[:, 1]>0),\n",
    "                          np.bitwise_and(current[:, 0] < 1, current[:, 1] < 1))\n",
    "\n",
    "    current = current[mask]\n",
    "    best = sorted(current, key=lambda x: eval_boulders(*x))[:μ]\n",
    "    best = np.array(best)\n",
    "\n",
    "    all_ += ax.plot(*current.T, 'o', color='#aaaaaa')\n",
    "    all_ += ax.plot(*np.array(best).T, 'o', color='#aa3a3a')\n",
    "\n",
    "    eigval, eigvec = sl.eig(cov)\n",
    "    for i, v in enumerate(eigval):\n",
    "        all_ += ax.plot(*np.c_[avg - 2*np.sqrt(5.991)*v.real*eigvec[:, i],\n",
    "                               avg + 2*np.sqrt(5.991)*v.real*eigvec[:, i]], '-k', lw=2)\n",
    "    \n",
    "    return all_\n",
    "\n",
    "animation.FuncAnimation(fig, update, init_func=init, frames=15, interval=500, blit=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La convergence est similaire à celle de l'exemple précédent en une dimension. Il est intéressant de voir l'évolution de la matrice de covariance, représentée ici par les directions/dimensions de ses vecteurs propres.\n",
    "\n",
    "### Mais voilà...\n",
    "\n",
    "En pratique, ça ne peut pas fonctionner comme ça... Souvenez-vous que:\n",
    "1. ce qui fonctionne en dimension 2 ne fonctionne pas nécessairement en dimension supérieure (malédiction de la dimension);\n",
    "2. on peut être piégé dans de mauvais minima locaux à cause du bruit;\n",
    "3. les métaphores fleurissent pour comparer stratégie d'évolution (fitness function, generation, matrice de covariance) et descente du gradient (objective function, iteration, matrice Hessienne); et la descente de gradient à pas constant ne fonctionne pas dans le cas général...\n",
    "\n",
    "\n",
    "Du coup, on va plutôt écrire qu'on recherche une population sous la forme :\n",
    "$$x_i \\sim m + \\sigma \\mathcal{N_i}(0, C)$$\n",
    " \n",
    "avec :\n",
    "\n",
    "- $m$, la moyenne de l'échantillon précédent (disons pour le moment, les $\\mu$ meilleurs parents),\n",
    "- $C$, une matrice de covariance,\n",
    "- $\\sigma$, un pas d'itération.\n",
    "\n",
    "Intuitivement, $m$ situe le voisinage de la meilleure solution trouvée jusqu'ici, $C$ donne la forme de l'ellipsoïde, et $\\sigma$ est un pas d'itération (similaire au pas de la descente de gradient).\n",
    "\n",
    "La mise à jour de $m$ est presque directe, celle de $\\sigma$ et de C va être un peu plus complexe...\n",
    "\n",
    "### Mise à jour de $m$, stratégies d'évolution\n",
    "\n",
    "- Stratégie élitiste $(\\mu + \\lambda)-$ES : sélection parmi les parents et les nouveaux échantillons;\n",
    "- Stratégie non-élitiste $(\\mu, \\lambda)$-ES: sélection parmi les nouveaux échantillons seulement (exemple ci-dessus).\n",
    "\n",
    "En CMA-ES, la stratégie classique est $({\\mu}/{\\mu_w}, \\lambda)-$ES, c'est à dire avec **sélection parmi les nouveaux échantillons et pondération des échantillons en fonction de leur score**: on trie les échantillons $x_i$ par ordre décroissant de score, et on fait un produit scalaire avec un vecteur $w$ de poids décroissants:\n",
    "\n",
    "$m \\leftarrow \\sum_{i=1}^{\\mu}w_i\\cdot x_i = m + \\sigma y_w = m + \\sigma\\sum_{i=1}^\\mu w_i \\cdot y_i$ avec $\\sum w_i = 1$ et $\\mu_w = \\dfrac{1}{\\sum w_i^2} \\sim \\dfrac{\\lambda}{4}$\n",
    "\n",
    "Cette recombinaison pondérée est équivalente à un mécanisme de sélection.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "**Note importante**: Nous allons voir beaucoup de paramètres défiler, mais la bonne nouvelle est que les paramètres par défaut fonctionnent a priori bien quel que soit le problème. En pratique, le seul argument du CMA-ES que vous pourriez avoir à régler est la *taille de la population*.\n",
    "</div>\n",
    "\n",
    "### Mise à jour de $\\sigma$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7, 7))\n",
    "ax = fig.gca()\n",
    "\n",
    "it = 4\n",
    "\n",
    "ax.contour(X, Y, Z, alpha=.5)\n",
    "\n",
    "ax.plot(*np.asarray(avgs).T, '-k', lw=2)\n",
    "\n",
    "ax.arrow(avgs[0][0], avgs[0][1],\n",
    "         avgs[it][0] - avgs[0][0], avgs[it][1] - avgs[0][1],\n",
    "         fc='r', ec='r', lw=2, length_includes_head=True,\n",
    "         head_width=.01)\n",
    "\n",
    "ax.axis('equal')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour la mise à jour de $\\sigma$, l'intuition repose sur le rapport entre la longueur du chemin parcouru par la moyenne de l'échantillon à chaque itération (en noir) et le chemin direct de la moyenne initiale vers la moyenne à l'échantillon courant (en rouge). Si le chemin noir « tourne en rond », alors il faut réduire $\\sigma$; au contraire, si le chemin noir parcourt l'équivalent du chemin rouge mais en plus d'itérations, il faut augmenter $\\sigma$.\n",
    "\n",
    "On initialise $p_\\sigma = 0$, $c_\\sigma \\sim 4/n$ et $d_\\sigma \\sim 1$. Intuitivement, $p_\\sigma$ représente l'évolution du trait noir.\n",
    "\n",
    "$$p_\\sigma \\leftarrow (1 - c_\\sigma) p_\\sigma + \\sqrt{1-(1-c_\\sigma)^2} \\sqrt{\\mu_w} \\cdot y_w$$\n",
    "\n",
    "Note : Le terme en $\\sqrt{1-(1-c_\\sigma)^2}$ est un facteur de normalisation.\n",
    "\n",
    "$$\\sigma \\leftarrow \\sigma \\cdot e^{\\dfrac{c_\\sigma}{d_\\sigma}\\left(\\dfrac{||p_\\sigma||}{E ||\\mathcal{N}(0, I)||}-1\\right)}$$\n",
    "\n",
    "Si le terme dans l'exponentielle est négatif, $\\sigma$ diminue, s'il est positif $\\sigma$ augmente.\n",
    "\n",
    "### Mise à jour de la matrice de covariance (CMA)\n",
    "\n",
    "La matrice de covariance va être adaptée suivant deux axes (en plus d'une inertie suivant son historique) :\n",
    "\n",
    "- l'évolution du chemin parcouru (*rank-one update*) : la matrice de covariance va être déformée dans le sens de parcours de $m$ ;\n",
    "\n",
    "$$p_C \\leftarrow (1 - c_C) p_C + \\sqrt{1-(1-c_C)^2} \\sqrt{\\mu_w} \\cdot y_w$$\n",
    "$$C \\leftarrow (1 - c_{cov})\\, C + c_{cov}\\, p_c\\,p_c^T$$\n",
    "\n",
    "- l'évolution de la matrice de covariance relative à la distribution des $\\mu$ meilleurs points (*rank-$\\mu$ update*).\n",
    "\n",
    "$$C_\\mu = \\sum_{i=1}^{\\mu} w_i\\,y_i\\, y_i^T$$\n",
    "$$C \\leftarrow (1 - c_{cov})\\, C + c_{cov}\\,C_\\mu$$\n",
    "\n",
    "\n",
    "avec $c_{cov} \\sim \\dfrac{\\mu_w}{n^2}$\n",
    "\n",
    "En pratique, on combine en pondérant ces deux stratégies avec deux coefficients.\n",
    "\n",
    "### L'algorithme complet sur le problème précédent\n",
    "\n",
    "On utilise un module Python clé en main pour cet algorithme.\n",
    "\n",
    "A priori la population (le paramètre $\\lambda$) peut être laissé à sa valeur par défaut (qui dépend de la dimension de l'espace de solution). Pour l'animation courante, le paramètre par défaut est 6, mais il est un peu grossi pour une animation visuellement un peu plus parlante.\n",
    "\n",
    "On n'a pas accès à la matrice de covariance et au pas utilisé par l'algorithme à chaque itération, alors la croix tracée est reformée à partir des points tirés par l'algorithme..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cma\n",
    "\n",
    "fig = plt.figure(figsize=(7, 7))\n",
    "ax = fig.gca()\n",
    "\n",
    "ax.contour(X, Y, Z, alpha=.5)\n",
    "all_ = []\n",
    "\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_ylim([0, 1])\n",
    "\n",
    "\n",
    "def cma_exec():\n",
    "\n",
    "    es = cma.CMAEvolutionStrategy(2 * [0.5], .5, {'popsize': 15})\n",
    "\n",
    "    while not es.stop():\n",
    "        x = np.asarray(es.ask())\n",
    "        yield x\n",
    "        es.tell(x, [eval_boulders(*x_) for x_ in x])\n",
    "        \n",
    "def update(x):\n",
    "    global all_\n",
    "    [a.remove() for a in all_]\n",
    "    all_.clear()\n",
    "    \n",
    "    avg, cov = np.mean(x, axis=0), np.cov(x.T)\n",
    "    all_ += ax.plot(*x.T, 'o', color='#aa3a3a')\n",
    "    \n",
    "    eigval, eigvec = sl.eig(cov)\n",
    "    for i, v in enumerate(eigval):\n",
    "        all_ += ax.plot(*np.c_[avg - 2*np.sqrt(5.991)*v.real*eigvec[:, i],\n",
    "                               avg + 2*np.sqrt(5.991)*v.real*eigvec[:, i]], '-k', lw=2)\n",
    "        \n",
    "    return all_\n",
    "\n",
    "animation.FuncAnimation(fig, update, frames=cma_exec, interval=500, blit=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problème à optimiser\n",
    "\n",
    "On cherche à placer les villes européennes suivantes sur une carte en ne connaissant que les distances les séparant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stochastic.data import cities, distances\n",
    "\n",
    "n = len(cities)\n",
    "print(\n",
    "    \"{} cities:\\n  {}\".format(\n",
    "        n, \"\\n  \".join(\n",
    "            [\" \".join([format(el, '<10')\n",
    "                       for el in cities[8*i:8*(i+1)]])\n",
    "             for i in range(4)]\n",
    "        )\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La matrice des distances suivante est fournie.  \n",
    "**Note:** Elle a été calculée à partir des vraies coordonnées lat/lon de ces villes puis normalisée, mais l'idée est de donner des coordonnées x-y euclidiennes à ces villes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>Questions :</b>\n",
    "\n",
    "<ul>\n",
    "<li>Modéliser le problème par une fonction à optimiser puis le résoudre avec l'algorithme CMA-ES.</li>\n",
    "<li>Afficher sur une carte la position des villes.</li>\n",
    "<li>La méthode `cma.fmin` prend en argument optionnel le gradient de la fonction à optimiser pour guider plus précisément la recherche. Comparer les nombres d'itérations avec sans gradient</li>\n",
    "<li>Y aurait-il une méthode plus efficace que le CMA-ES pour résoudre ce problème?</li>\n",
    "</ul>\n",
    "</div>\n",
    "\n",
    "- Il est recommandé d'utiliser la méthode `cma.fmin()` (voir l'aide) plutôt que la méthode manuelle ci-dessus (qui nous a servi à afficher la convergence).\n",
    "- La méthode `plt.annotate` permettra d'afficher le nom de la ville sur un plot à côté du point associé à ses coordonnées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/03-cities.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = cma.fmin(func, x0.ravel(), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = cma.fmin(func, x0.ravel(), 1, gradf=func_der)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize as sopt\n",
    "\n",
    "solution = sopt.fmin_bfgs(func, x0.ravel(), fprime=func_der, retall=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-processing\n",
    "\n",
    "Comme toutes les rotations et symétries (miroir) de notre carte sont des solutions équivalentes de notre problème, on va remettre la carte dans le bon sens:\n",
    "- Rome et Copenhague sont à la même longitude (ou presque)\n",
    "- À partir de deux villes dont on sait qu'elles sont à l'Est/Ouest l'une de l'autre, on décide si un miroir est nécessaire.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load solutions/03-postprocess.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load solutions/03-plot_cities.py\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
